{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Building a Database for Crime Reports\n",
    "\n",
    "Application of POSTGRES fundamentals to set up a database for storing crime data.\n",
    "\n",
    "The goal of the project is to create and set up a database and populate schemas, tables and users with the most appropriate datatypes and applying best practices.\n",
    "\n",
    "Two major user groups will be set up:\n",
    "- `readonly`: permission-level to read data only (for data analysts, scientists and those who want a dataview of the reports.\n",
    "- `readwrite`: permission-level to read and alter data, but not to drop tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Database & Schemas\n",
    "\n",
    "Database Name: `crime_db` and Schema Name: `crimes` to store all tables containing data. The database has not been created yet, so we will log in with DataQuest's default user account for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "database \"crime_db\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-93401eba98cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CREATE DATABASE crime_db;\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# End Autocommit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: database \"crime_db\" already exists\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname='dq', user='dq')\n",
    "# Start Autocommit to Create Databases\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")\n",
    "# End Autocommit \n",
    "conn.autocommit = False\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='crime_db', user='dq')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA crimes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Export: Inspect Headers and First Row\n",
    "\n",
    "Header row to be copied to `col_headers` and first row to `first_row`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('boston.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    col_headers = next(reader)\n",
    "    first_row = next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['incident_number',\n",
       " 'offense_code',\n",
       " 'description',\n",
       " 'date',\n",
       " 'day_of_the_week',\n",
       " 'lat',\n",
       " 'long']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '619',\n",
       " 'LARCENY ALL OTHERS',\n",
       " '2018-09-02',\n",
       " 'Sunday',\n",
       " '42.35779134',\n",
       " '-71.13937053']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Column Values using a Function\n",
    "\n",
    "The function `get_col_value_set` will be useful for these two reasons:\n",
    "1. Checking whether an enumerated `datatype` might be a good choice for representing a column.\n",
    "2. Computing the maximum length of any text-like column to select appropriate sizes for `VARCHAR` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t298329\n",
      "offense_code\t219\n",
      "description\t239\n",
      "date\t1177\n",
      "day_of_the_week\t7\n",
      "lat\t18177\n",
      "long\t18177\n"
     ]
    }
   ],
   "source": [
    "def get_col_set(csv_filename, col_index):\n",
    "    values = set()\n",
    "    with open(csv_filename, 'r') as f:\n",
    "        next(f) # to skip the header\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            values.add(row[col_index])\n",
    "    return values\n",
    "\n",
    "for value in range(len(col_headers)):\n",
    "    values = get_col_set('boston.csv', value)\n",
    "    print(col_headers[value], len(values), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Max Length of Long-Text columns\n",
    "\n",
    "Some columns can have paragraphs, so we'll count the number of characters in the `description` column to find out what `datatype` we should assign it to. `day_of_the_week` are days of the week and Wednesday has the most characters, so it's not a good candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n"
     ]
    }
   ],
   "source": [
    "print(col_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "descriptions = get_col_set('boston.csv', 2) # Description is at Index 2\n",
    "max_length = 0\n",
    "for desc in descriptions:\n",
    "    max_length = max(max_length, len(desc))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "\n",
    "Let's first analyze all column names and find out what datatype should we assign on each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "print(col_headers)\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that `incident_number` and `offense_code` should be `integer numbers`, as they appear as natural numbers. `Description` should be assigned to `string` with at least 58 characters, but the `day_of_the_week` should be converted into an `enum type` table, since there are only seven possible values. `date` as `date`, and `lat` and `long` as `decimals` since they are floats and can be a negative number.\n",
    "\n",
    "Let's create the table `boston_crimes`, but we'll execute the `weekday` enum table before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    CREATE TYPE weekday AS ENUM(\n",
    "        'Monday', 'Tuesday', 'Wednesday',\n",
    "        'Thursday', 'Friday', 'Saturday',\n",
    "        'Sunday'\n",
    "    );\n",
    "\"\"\")\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE crimes.boston_crimes(\n",
    "        incident_number INTEGER PRIMARY KEY,\n",
    "        offense_code INTEGER,\n",
    "        description VARCHAR(100),\n",
    "        date DATE,\n",
    "        day_of_the_week weekday,\n",
    "        lat decimal,\n",
    "        long decimal\n",
    "    );\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into Table\n",
    "\n",
    "Let's use the `copy_expert` method to export the csv data into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298329\n"
     ]
    }
   ],
   "source": [
    "with open(\"boston.csv\", 'r') as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "    cur.execute(\"SELECT * FROM crimes.boston_crimes;\")\n",
    "print(len(cur.fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revoke Privileges\n",
    "\n",
    "As per best practices in database creation, we have to revoke all privileges from the public schema and group (both called `public`) and since we created both the table and the schema, they automatically inherit the grant privileges on public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-Only & Read-Write Group creation\n",
    "\n",
    "Let's create the `readonly` and `readwrite` groups with `NOLOGIN`, per best practices. Only difference is that `readonly` is for data analysts and `readwrite` is for data scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadWrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User creation\n",
    "\n",
    "Users `data_analyst` and `data_scientist` will be created.\n",
    "1. Data Analysts will have `readonly` privileges with password `secret1`\n",
    "2. Data Scientists will have `readwrite` privileges with password `secret2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Testing\n",
    "\n",
    "For our final step, we will test the database setup using SQL queries on the `pg_roles` table and `information_schema.table_privileges`.\n",
    "\n",
    "In the `pg_roles` table we will check database related privileges and for that we will look at the following columns:\n",
    "\n",
    "- `rolname`: The name of the user / group that the privilege refers to.\n",
    "- `rolsuper`: Whether this user / group is a super user. It should be set to False on every user / group that we have created.\n",
    "- `rolcreaterole`: Whether user / group can create users, groups or roles. It should be False on every user / group that we have created.\n",
    "- `rolcreatedb`: Whether user / group can create databases. It should be False on every user / group that we have created.\n",
    "- `rolcanlogin`: Whether user / group can login. It should be True on the users and False on the groups that we have created.\n",
    "\n",
    "In the `information_schema.table_privileges` we will check privileges related to SQL queries on tables. We will list the privileges of each group that we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conn.close()\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"crime_db\", user=\"dq\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb, rolcanlogin FROM pg_roles\n",
    "    WHERE rolname IN ('readonly', 'readwrite', 'data_analyst', 'data_scientist');\n",
    "\"\"\")\n",
    "for user in cur:\n",
    "    print(user)\n",
    "print()\n",
    "# check privileges\n",
    "cur.execute(\"\"\"\n",
    "    SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee IN ('readonly', 'readwrite');\n",
    "\"\"\")\n",
    "for user in cur:\n",
    "    print(user)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
